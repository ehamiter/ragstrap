from pathlib import Path
from datetime import datetime
import json
import re

from .language import detect_languages


def read_first_paragraph(path: Path) -> str | None:
    """
    Extract the first meaningful prose paragraph from a README-like file.
    Skips HTML, images, and non-textual content.
    """
    try:
        text = path.read_text(errors="ignore")
    except FileNotFoundError:
        return None

    paragraphs = re.split(r"\n\s*\n", text)

    for p in paragraphs:
        clean = p.strip()

        if not clean:
            continue

        # Skip HTML blocks
        if clean.startswith("<"):
            continue

        # Skip image-only markdown
        if clean.startswith("![") or clean.startswith("[!["):
            continue

        # Require some alphabetic content
        if sum(c.isalpha() for c in clean) < 40:
            continue

        # Collapse newlines
        return clean.replace("\n", " ")

    return None


def detect_readme(raw: Path) -> Path | None:
    for name in ("README.md", "README.rst", "README.txt"):
        candidate = raw / name
        if candidate.exists():
            return candidate
    return None


def list_dirs(raw: Path) -> list[str]:
    return sorted(
        p.name for p in raw.iterdir()
        if p.is_dir() and not p.name.startswith(".")
    )


def list_files(raw: Path) -> list[str]:
    return sorted(
        p.name for p in raw.iterdir()
        if p.is_file()
    )

def generate_index(reference_dir: Path):
    raw = reference_dir / "raw"
    meta_path = reference_dir / "meta.json"

    meta = {}
    if meta_path.exists():
        meta = json.loads(meta_path.read_text())

    readme = detect_readme(raw)
    summary = read_first_paragraph(readme) if readme else None

    primary_language, secondary_languages = detect_languages(raw)
    meta["language"] = primary_language
    if secondary_languages:
        meta["secondary_languages"] = secondary_languages
    meta_path.write_text(json.dumps(meta, indent=2))

    dirs = list_dirs(raw)
    files = list_files(raw)

    lines: list[str] = []

    lines.append(f"# {meta.get('name', 'Library')} â€” Local Reference")
    lines.append("")
    lines.append(f"> Source: {meta.get('source', 'unknown')}")
    lines.append(f"> Fetched at: {meta.get('fetched_at', 'unknown')}")
    lines.append(f"> Generated by ragstrap")
    if primary_language != "unknown":
        lines.append(f"> Language: {primary_language}")
    lines.append("")

    if summary:
        lines.append("## What this library is")
        lines.append("")
        lines.append(summary)
        lines.append("")

    if dirs:
        lines.append("## Available documentation")
        lines.append("")
        for d in dirs:
            lines.append(f"- `{d}/`")
        lines.append("")

    if files:
        lines.append("## Top-level files")
        lines.append("")
        for f in files:
            lines.append(f"- `{f}`")
        lines.append("")

    lines.append("## How to use this reference")
    lines.append("")
    lines.append(
        "This directory contains a local, authoritative snapshot of the library's "
        "documentation and examples. Prefer these files over external sources when "
        "working with the library or when providing context to an LLM."
    )
    lines.append("")

    index_path = reference_dir / "index.md"
    index_path.write_text("\n".join(lines))

